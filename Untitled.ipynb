{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1d87794f",
   "metadata": {},
   "source": [
    "Задача: составление прозрачной статистики для администрации города, основанной на отзывах о площадках."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0129c25d",
   "metadata": {},
   "source": [
    "Суммаризация отзывов пользователей, оценка их эмоциональной тональности и вывод ключевых слов может значительно помочь администрации города: с принятием решений по реставрации площадок, необходимости постройки новых площадок, пониманием нужд жителей города "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5b6b52fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: transformers in c:\\users\\vadim\\appdata\\roaming\\python\\python311\\site-packages (4.46.3)\n",
      "Requirement already satisfied: filelock in c:\\programdata\\anaconda3\\lib\\site-packages (from transformers) (3.9.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in c:\\users\\vadim\\appdata\\roaming\\python\\python311\\site-packages (from transformers) (0.26.3)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\vadim\\appdata\\roaming\\python\\python311\\site-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from transformers) (23.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from transformers) (6.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\programdata\\anaconda3\\lib\\site-packages (from transformers) (2022.7.9)\n",
      "Requirement already satisfied: requests in c:\\programdata\\anaconda3\\lib\\site-packages (from transformers) (2.31.0)\n",
      "Requirement already satisfied: tokenizers<0.21,>=0.20 in c:\\users\\vadim\\appdata\\roaming\\python\\python311\\site-packages (from transformers) (0.20.3)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in c:\\users\\vadim\\appdata\\roaming\\python\\python311\\site-packages (from transformers) (0.4.5)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\programdata\\anaconda3\\lib\\site-packages (from transformers) (4.65.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\vadim\\appdata\\roaming\\python\\python311\\site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (2024.10.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\vadim\\appdata\\roaming\\python\\python311\\site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.12.2)\n",
      "Requirement already satisfied: colorama in c:\\programdata\\anaconda3\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests->transformers) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests->transformers) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests->transformers) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests->transformers) (2023.7.22)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "!pip install transformers\n",
    "from transformers import AutoModelForSequenceClassification\n",
    "from transformers import BertTokenizerFast\n",
    "from transformers import AutoTokenizer, T5ForConditionalGeneration\n",
    "# Модель для оценивания тональности отзыва\n",
    "tokenizer = BertTokenizerFast.from_pretrained('blanchefort/rubert-base-cased-sentiment-rusentiment')\n",
    "model = AutoModelForSequenceClassification.from_pretrained('blanchefort/rubert-base-cased-sentiment-rusentiment', return_dict=True)\n",
    "\n",
    "@torch.no_grad()\n",
    "def predict(text):\n",
    "    inputs = tokenizer(text, max_length=512, padding=True, truncation=True, return_tensors='pt')\n",
    "    outputs = model(**inputs)\n",
    "    predicted = torch.nn.functional.softmax(outputs.logits, dim=1)\n",
    "    predicted = torch.argmax(predicted, dim=1).numpy()\n",
    "    return predicted\n",
    "# Модель для суммаризации отзывов\n",
    "model_name = \"IlyaGusev/rut5_base_sum_gazeta\"\n",
    "tokenizer_summr = AutoTokenizer.from_pretrained(model_name)\n",
    "model_summr = T5ForConditionalGeneration.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "22efecb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "df = pd.read_csv(\"sample_reviews.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fd344bdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = df[df[\"ground_id\"] == 4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "357eca21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ground_id</th>\n",
       "      <th>review</th>\n",
       "      <th>review_value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>4</td>\n",
       "      <td>Дорожки на трассе уже в ужасном состоянии. В н...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>4</td>\n",
       "      <td>Очень разочарован состоянием беговой трассы. П...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>4</td>\n",
       "      <td>Трасса по факту — это отличное место для бега,...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>4</td>\n",
       "      <td>Беговая трасса оставляет желать лучшего. Покры...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    ground_id                                             review  review_value\n",
       "12          4  Дорожки на трассе уже в ужасном состоянии. В н...             2\n",
       "13          4  Очень разочарован состоянием беговой трассы. П...             2\n",
       "14          4  Трасса по факту — это отличное место для бега,...             1\n",
       "15          4  Беговая трасса оставляет желать лучшего. Покры...             2"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "41416dbe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Дорожки на трассе уже в ужасном состоянии. В некоторых местах покрытие изношено до такой степени, что можно повредить суставы. Реновация однозначно нужна! С таким состоянием трассы бегать небезопасно.',\n",
       " 'Очень разочарован состоянием беговой трассы. Покрытие старое, изношенное, а местами и вовсе в ямах. Бегать по таким дорожкам — это риск для здоровья. Надеюсь, в ближайшее время её отремонтируют.',\n",
       " 'Трасса по факту — это отличное место для бега, но из-за изношенного покрытия бегать стало неудобно. Не раз можно споткнуться о неровности или камни, которые торчат из асфальта. Нужна срочная реновация, чтобы было безопасно и комфортно тренироваться.',\n",
       " 'Беговая трасса оставляет желать лучшего. Покрытие местами совсем изношено, дорожки очень твердые и некомфортные. Надо бы уже привести трассу в порядок, а то бегать здесь не так приятно, как хотелось бы.']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample[\"review\"].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "54547c52",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from collections import defaultdict\n",
    "def get_sentiment_category(reviews):\n",
    "    sentiment_value = 0\n",
    "    for j in range(len(reviews)):\n",
    "        sentiment = predict(reviews[j])[0]\n",
    "        if(sentiment == 1):\n",
    "            sentiment_value+=1\n",
    "        elif(sentiment==2):\n",
    "            sentiment_value-=1\n",
    "    mean_sentiment_value = sentiment_value/len(reviews)\n",
    "    sentiment_proportion = ((mean_sentiment_value + 1)/2)\n",
    "    if(sentiment_proportion >= 0 and sentiment_proportion <=0.2):\n",
    "        sentiment_catrgory = \"Крайне негативные\"\n",
    "    elif(sentiment_proportion > 0.2 and sentiment_proportion <=0.4):\n",
    "        sentiment_catrgory = \"В основном негативные\"\n",
    "    elif(sentiment_proportion > 0.4 and sentiment_proportion <=0.6):\n",
    "        sentiment_catrgory = \"Смешанные\"\n",
    "    elif(sentiment_proportion > 0.6 and sentiment_proportion <=0.8):\n",
    "        sentiment_catrgory = \"В основном положительные\"\n",
    "    elif(sentiment_proportion > 0.8 and sentiment_proportion <=1):\n",
    "        sentiment_catrgory = \"Крайне положительные\"\n",
    "    return sentiment_catrgory\n",
    "\n",
    "# Функция получения ключевых слов\n",
    "def get_key_aspects(reviews):\n",
    "    def get_sentiment_score(text):\n",
    "        inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, max_length=512, padding=True)\n",
    "        with torch.no_grad():\n",
    "            outputs = model(**inputs)\n",
    "        scores = torch.nn.functional.softmax(outputs.logits, dim=1)\n",
    "        positive_score = scores[0][2].item() \n",
    "        negative_score = scores[0][0].item() \n",
    "        return positive_score - negative_score  \n",
    "\n",
    "    # Генерация множества слов и биграмм(последовательности из двух слов)\n",
    "    vectorizer = CountVectorizer(ngram_range=(1, 2), token_pattern=r'\\b\\w+\\b')\n",
    "    vectorizer.fit(reviews)\n",
    "    ngrams = vectorizer.get_feature_names_out()\n",
    "\n",
    "    # Словарь для хранения тональности каждого элемента\n",
    "    sentiment_scores = defaultdict(float)\n",
    "\n",
    "    # Оценка тональности для каждого элемента множества\n",
    "    for ngram in ngrams:\n",
    "        sentiment_scores[ngram] = get_sentiment_score(ngram)\n",
    "    # Сортировка по тональности\n",
    "    sorted_aspects = sorted(sentiment_scores.items(), key=lambda x: x[1], reverse=True)\n",
    "    # Выбор топ-5 положительных и топ-5 отрицательных\n",
    "    top_positive = sorted_aspects[:3]\n",
    "    top_negative = sorted_aspects[-3:]\n",
    "\n",
    "    return {\n",
    "        \"top_positive\": top_positive,\n",
    "        \"top_negative\": top_negative\n",
    "    }\n",
    "# Функция суммаризации набора отзвывов\n",
    "def get_summary(text):\n",
    "    input_text = (\"\\n\").join(text)\n",
    "    input_ids = tokenizer_summr(\n",
    "        [input_text],\n",
    "        max_length=600,\n",
    "        add_special_tokens=True,\n",
    "        padding=\"max_length\",\n",
    "        truncation=True,\n",
    "        return_tensors=\"pt\"\n",
    "    )[\"input_ids\"]\n",
    "    output_ids = model_summr.generate(\n",
    "        input_ids=input_ids,\n",
    "        no_repeat_ngram_size=4,\n",
    "        max_length=100,\n",
    "    )[0]\n",
    "\n",
    "    summary = tokenizer_summr.decode(output_ids, skip_special_tokens=True)\n",
    "    return summary\n",
    "\n",
    "\n",
    "def analyze(df): \n",
    "    sport_grounds = df[\"ground_id\"].unique()\n",
    "    import numpy as np\n",
    "    sentiment_col = [] \n",
    "    mean_review_value_col = []\n",
    "    ground_id_col = []\n",
    "    key_positive_aspects_col = []\n",
    "    key_negative_aspects_col = []\n",
    "    summaries =[]\n",
    "    for i in sport_grounds:\n",
    "        temp = df[df[\"ground_id\"] == i]\n",
    "        reviews = temp[\"review\"].to_list()\n",
    "        ground_id_col.append(i)\n",
    "        mean_review_value = np.mean(temp[\"review_value\"])\n",
    "        mean_review_value_col.append(mean_review_value)\n",
    "        sentiment_col.append(get_sentiment_category(reviews))\n",
    "        key_aspects = get_key_aspects(reviews) \n",
    "        key_positive_aspects_col.append(key_aspects[\"top_positive\"])\n",
    "        key_negative_aspects_col.append(key_aspects[\"top_negative\"])\n",
    "        summaries.append(get_summary(reviews))\n",
    "\n",
    "    result = pd.DataFrame({\n",
    "        'ground_id': ground_id_col,\n",
    "        'mean_review_value': mean_review_value_col,\n",
    "        'sentiment': sentiment_col,\n",
    "        'key_positive_aspects': key_positive_aspects_col,\n",
    "        'key_negative_aspects': key_negative_aspects_col,\n",
    "        'review_summary':summaries\n",
    "    })\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "70d775e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_analysis = analyze(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "3484d7f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'В ближайшее время нужна срочная реновация беговой трассы, чтобы было безопасно и комфортно тренироваться. Покрытие уже в ужасном состоянии, а в некоторых местах покрытие изношено до такой степени, что можно повредить суставы.'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_analysis[\"review_summary\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "5f7c9d77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('асфальта', -0.9949048517737538),\n",
       " ('суставы', -0.9949382407357916),\n",
       " ('беговой трассы', -0.9950577021809295)]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_analysis[\"key_negative_aspects\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "fa5d2bc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_analysis.to_csv('sample_analysis.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cf5e295",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
